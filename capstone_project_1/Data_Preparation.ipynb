{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(diry, txt, url_f, url_b):\n",
    "    # read files and merge those files based on Zip Code and Time \n",
    "    files = glob.glob(diry)\n",
    "    for i in range(len(files)):    # read fire incident report files\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(files[i], encoding='ISO-8859-1', index_col=None, na_values='')\n",
    "        else:\n",
    "            df1 = pd.read_csv(files[i], encoding='ISO-8859-1', index_col=None, na_values='')\n",
    "            df1.columns = df.columns\n",
    "            df = pd.concat([df, df1], ignore_index=True)\n",
    "    weather = pd.read_csv(txt, sep=',', na_values='', parse_dates=['Date']) # read hourly weather data\n",
    "    \n",
    "    lst = []\n",
    "    for n in range(1,6):\n",
    "        url =  url_f + str(n) + '.' + url_b\n",
    "        lst.extend(extract(url))\n",
    "    col = ['Index', 'Zip Code', 'Lat_Log', 'Location', 'Population', 'Population_Density', 'National Rank'] \n",
    "    pop = pd.DataFrame(np.array(lst).reshape(-1, 7), columns=col)\n",
    "    \n",
    "    \n",
    "    df = df.dropna(how='all') # pre-clean data for Zip code and time for merging files \n",
    "    df['Time'] = df['Alarm Date'] + ' ' + df['Alarm Time']\n",
    "    df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%m/%d/%Y %H')\n",
    "    df['Zip'] = df['Zip'].astype(str).apply(lambda x: \"0\" + x[:4] if len(x) ==4 or len(x) == 6 else x)\n",
    "    df['Zip'] = df['Zip'].apply(lambda x: np.NaN if x[:2] != \"01\" and x[:2] != \"02\" else x)\n",
    "    \n",
    "    weather['Date'] = weather['Date'] + pd.to_timedelta(weather['Hour'], unit='h')\n",
    "    weather['Date'] = weather['Date'].dt.strftime('%m/%d/%Y %H')\n",
    "    \n",
    "     \n",
    "    df = df.merge(weather, how='left', left_on='Time', right_on='Date') # merge files based on time and zipcode\n",
    "    df = df.merge(pop, how='left', left_on='Zip', right_on='Zip Code')\n",
    "    \n",
    "    return df, pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(link):\n",
    "    # Scrape population data based on zip code from website\n",
    "    page = urllib.urlopen(link)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    html = soup.findAll('td', attrs={'class':'report_data'})\n",
    "    return [text.text for text in html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Input files\n",
    "    incident = 'E://springboard//capstone_project_1//raw_data//fire/*.csv'\n",
    "    weat_txt = 'E://springboard//capstone_project_1//raw_data//weather/KBOS_hourly.txt'\n",
    "    pop_url_f = 'http://zipatlas.com/us/ma/zip-code-comparison/population-density.'\n",
    "    pop_url_b = 'htm'\n",
    "    total_data, pop_data = read_file(incident, weat_txt, pop_url_f, pop_url_b)\n",
    "    total_data.to_csv('E://springboard//capstone_project_1//raw_data/fire_weather_pop.csv') \n",
    "    pop_data.to_csv('E://springboard//capstone_project_1//raw_data//population/pop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2862: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2862: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
