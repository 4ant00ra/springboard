{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(df):\n",
    "    # extract useful data and combine columns\n",
    "    \n",
    "    # strip space before and after words\n",
    "    df.sort_values(by=['Incident Number'], inplace=True)\n",
    "    df.iloc[:, 5:6] = df.apply(lambda x: x.astype(str).str.strip())\n",
    "    df.iloc[:, 8:24] = df.apply(lambda x: x.astype(str).str.strip())\n",
    "    \n",
    "    # extract useful information\n",
    "    df = df.dropna(subset=['Incident Type'])\n",
    "    df['Incident Type'] = df['Incident Type'].apply(lambda x: x[0] if x[0].isdigit() else '')\n",
    "    df['District'] = df['District'].map(lambda x: x.strip('0') if len(x) == 2 and x[0] == '0' else x)\n",
    "    df['District'] = df['District'].map(lambda x: '' if x.isdigit() is False else x)\n",
    "    df['District'] = df['District'].apply(lambda x: str(x) if type(x) != str else x)\n",
    "    df['Property Use'] = df['Property Use'].apply(lambda x: x[0] if x.isdigit() else '')\n",
    "    df['Population'] = pd.to_numeric(df['Population'].astype(str).apply(lambda x: x.replace(',', '')), \n",
    "                                     errors='coerce')\n",
    "    df['Population_Density'] = pd.to_numeric(df['Population_Density'].astype(str).apply(lambda x: x.replace(',', '')),\n",
    "                                         errors='coerce')\n",
    "    df['WindDir'] = df['WindDir'].apply(lambda x: x[1:] if len(x) == 3 and x[0] == '0' else x)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    # combine address in one column\n",
    "    df['Main Address'] = df['Street Number'] + ' ' + df['Street Prefix']  + ' ' + df['Street Name'] +\\\n",
    "                         ' ' + df['Street Type'] + ' ' + df['Street Suffix']\n",
    "       \n",
    "    # clean Column     \n",
    "    df['Weather'] = df['Weather'].str.replace('\\-', '').str.replace('\\+', '')\n",
    "    df['Weather'] = df['Weather'].apply(lambda x: ' '.join([i for i in x.split() if i.isalpha()]))\n",
    "    df['Weather'] = df['Weather'].str.replace('FEW', 'CLD').str.replace('BKN', 'CLD').\\\n",
    "                                 str.replace('SCT', 'CLD').str.replace('OVC', 'CLD')\n",
    "    \n",
    "    df.loc[df['WindDir'] == '00', 'WindDir'] = '0'\n",
    "    df.loc[df['WindDir'] == '390', 'WindDir'] = '30'\n",
    "    wind = {'330':'N/NW', '340':'N/NW', '310':'NW', '320':'NW', '290':'W/NW', '300':'W/NW', '260':'W', '270':'W', \n",
    "        '280':'W', '240':'W/SW', '250':'W/SW', '220':'SW', '230':'SW', '200':'S/SW', '210':'S/SW', '170':'S', \n",
    "        '180':'S', '190':'S','150':'S/SE', '160':'S/SE', '130':'SE', '140':'SE', '110':'E/SE', '120':'E/SE', \n",
    "        '80':'E', '90':'E', '100':'E', '60':'E/NE', '70':'E/NE', '40':'NE', '50':'NE', '20':'N/NE', '30':'N/NE', \n",
    "        '350':'N', '360':'N', '10':'N', '0':'N'}\n",
    "    df['WindDir'] = df['WindDir'].map(wind)\n",
    "    \n",
    "    # fill empty blank or string \"nan\" with NaN\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True).replace('nan', np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    # drop or fill_missing values \n",
    "    \n",
    "    # drop NaN in column Incident Type\n",
    "    df = df.dropna(subset=['Incident Type'])\n",
    "    \n",
    "    # fill some vaues of Neighborhood and City Section with current values\n",
    "    df = df.dropna(subset=['Incident Type'])\n",
    "    df1 = df[(df.Neighborhood.notnull()) & df.Zip.notnull()].drop_duplicates()\n",
    "    dict_zip = dict(zip(df1.Zip, df1.Neighborhood))\n",
    "    df.loc[(df.Neighborhood.isnull()) & (df.Zip.notnull()), 'Neighborhood'] = \\\n",
    "                                         df.loc[(df.Neighborhood.isnull()) & \\\n",
    "                                                (df.Zip.notnull()), 'Zip'].map(dict_zip)\n",
    "        \n",
    "    \n",
    "    # fill missing values\n",
    "    df['Incident Description'].fillna('Unknown', inplace=True)\n",
    "    df['District'] = df['District'].fillna('Unknown')\n",
    "    df['Neighborhood'] = df['Neighborhood'].fillna('Unknown')\n",
    "    df['Zip'] = df['Zip'].fillna('00000')\n",
    "    df['Property Use'] = df['Property Use'].fillna('Unknown')\n",
    "    df['Property Description'] = df['Property Description'].fillna('None')\n",
    "    df['Main Address'].fillna('None', inplace=True)\n",
    "    df['Population'] = df['Population'].fillna(df['Population'].mean())\n",
    "    df['Population_Density'] = df['Population_Density'].fillna(df['Population_Density'].mean())\n",
    "    df['Precip'] = df['Precip'].fillna(0)\n",
    "    df['WindDir'].fillna('Unknown', inplace=True)\n",
    "    df['Location'].fillna('Unknown', inplace=True)\n",
    "    df['Location'] = df['Location'].apply(lambda x: x.split(',')[0] if ',' in x else x)\n",
    "    df.loc[df['Neighborhood'] == 'Allston-Brighton', 'Neighborhood'] = df[df['Neighborhood'] == \n",
    "                                                                          'Allston-Brighton']['Location']\n",
    "    df.loc[df['Neighborhood'] == 'Unknown', 'Neighborhood'] = df[df['Neighborhood'] == 'Unknown']['Location']\n",
    "    df.loc[df['Neighborhood'].str.contains('Newton'), 'Neighborhood'] = 'Newton'\n",
    "   \n",
    "    \n",
    "    # drop unuseful columns\n",
    "    drop_col = ['Street Number', 'Street Prefix', 'Street Name', 'Street Type', 'Street Suffix', 'xStreet Prefix', \n",
    "                'xStreet Name', 'xStreet Type', 'xStreet Suffix', 'Site', 'Date', 'Hour', 'Source', 'City Section', \n",
    "                'Index', 'Zip Code', 'National Rank', 'Address 2', 'Lat_Log', 'Location']\n",
    "    df.drop(drop_col, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = pd.read_csv('E://springboard//capstone_project_1//raw_data/fire_weather_pop.csv', encoding='ISO-8859-1', \n",
    "                  index_col=[0], dtype={'Zip':'category'})\n",
    "    data = extract(data)\n",
    "    data = normalize(data)\n",
    "    data = fill_na(data)\n",
    "    data.to_csv('E://springboard//capstone_project_1//clean_data/clean_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2802: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
